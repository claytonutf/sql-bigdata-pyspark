{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnw2GpLPYe7W"
      },
      "source": [
        "## Instalação das bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcZESyMveEqK"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfDNy354tHaC"
      },
      "outputs": [],
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "      .master(\"local[1]\") \\\n",
        "      .appName(\"Aula de Pyspark\") \\\n",
        "      .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UyB57KXuGjO"
      },
      "outputs": [],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dOQhzh6aj6V"
      },
      "source": [
        "# Criar dataframe a partir de um arquivo CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iH5MhppZWxJ",
        "outputId": "c25a2bc7-8dda-4bf4-a51e-07f9f4711ee5"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import (\n",
        "    StructType, StructField,\n",
        "    IntegerType, StringType, DoubleType, DateType\n",
        ")\n",
        "\n",
        "# Iniciar sessão Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LoadEmployeeCSV\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Definir schema explícito (recomendado para evitar erros)\n",
        "schema = StructType([\n",
        "    StructField(\"employee_id\", IntegerType(), True),\n",
        "    StructField(\"first_name\", StringType(), True),\n",
        "    StructField(\"last_name\", StringType(), True),\n",
        "    StructField(\"email\", StringType(), True),\n",
        "    StructField(\"phone_number\", StringType(), True),\n",
        "    StructField(\"hire_date\", DateType(), True),\n",
        "    StructField(\"job_id\", StringType(), True),\n",
        "    StructField(\"salary\", DoubleType(), True),\n",
        "    StructField(\"manager_id\", IntegerType(), True),\n",
        "    StructField(\"department_id\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# Carregar CSV\n",
        "df = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"false\") \\\n",
        "    .schema(schema) \\\n",
        "    .option(\"nullValue\", \"\") \\\n",
        "    .csv(\"employees.csv\")\n",
        "\n",
        "df.show(truncate=False)\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VMDrjVqZ9QZ"
      },
      "source": [
        "## Criar uma view para trabalhar com a API SQL do PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTm1hqF7Zkoo"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"employees\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FQWCRAfaJH2"
      },
      "outputs": [],
      "source": [
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT *\n",
        "    FROM employees\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySKfVS9nnZxT"
      },
      "outputs": [],
      "source": [
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "  employee_id,\n",
        "  first_name,\n",
        "  last_name,\n",
        "  hire_date\n",
        "FROM\n",
        "  employees;\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS0t2HrfncB6"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT count(*)\n",
        "    FROM employees\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NSR-XgpnhWV"
      },
      "outputs": [],
      "source": [
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "  employee_id,\n",
        "  first_name,\n",
        "  last_name,\n",
        "  COUNT(hire_date) AS total_hire_date\n",
        "FROM\n",
        "  employees\n",
        "GROUP BY\n",
        "  employee_id,\n",
        "  first_name,\n",
        "  last_name\n",
        "ORDER BY\n",
        "  COUNT(hire_date)\n",
        "\"\"\").show(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversão PySpark → Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executar query e converter para pandas\n",
        "df_pandas = spark.sql(\"\"\"\n",
        "    SELECT *\n",
        "    FROM employees\n",
        "\"\"\").toPandas()\n",
        "\n",
        "# Agora é um DataFrame pandas normal\n",
        "print(df_pandas.head())\n",
        "print(type(df_pandas))  # <class 'pandas.core.frame.DataFrame'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Atenção com grandes volumes de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Para datasets grandes, use limit ou filtros\n",
        "df_sample = spark.sql(\"\"\"\n",
        "    SELECT *\n",
        "    FROM employees\n",
        "    LIMIT 10000\n",
        "\"\"\").toPandas()\n",
        "\n",
        "# Ou filtre antes de converter\n",
        "df_filtered = spark.sql(\"\"\"\n",
        "    SELECT *\n",
        "    FROM employees\n",
        "    WHERE hire_date > '2020-01-01'\n",
        "\"\"\").toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversão Pandas → PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_vendas = pd.DataFrame({\n",
        "    'produto': ['Notebook', 'Mouse', 'Teclado', 'Monitor', 'Webcam', 'Headset'],\n",
        "    'quantidade': [15, 45, 30, 20, 25, 18],\n",
        "    'preco_unitario': [3500.00, 85.00, 250.00, 1200.00, 320.00, 180.00],\n",
        "    'categoria': ['Eletrônicos', 'Acessórios', 'Acessórios', 'Eletrônicos', 'Eletrônicos', 'Acessórios'],\n",
        "    'em_estoque': [True, True, False, True, True, False]\n",
        "})\n",
        "\n",
        "# Pandas → PySpark\n",
        "df_spark = spark.createDataFrame(df_pandas)\n",
        "\n",
        "# Registrar como tabela temporária\n",
        "df_spark.createOrReplaceTempView(\"vendas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_spark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Q21rGD0TAd"
      },
      "source": [
        "## Tarefa: Dataframe employees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-03CiLj0VGJ"
      },
      "source": [
        "1. Liste todos os funcionários cadastrados no DataFrame.\n",
        "\n",
        "2. Mostre o nome completo e o salário de cada funcionário.\n",
        "\n",
        "3. Quais funcionários foram contratados após o ano de 1988?\n",
        "\n",
        "4. Quais funcionários possuem um gerente definido?\n",
        "\n",
        "5. Qual é o salário médio dos funcionários?\n",
        "\n",
        "6. Quantos funcionários existem em cada departamento?\n",
        "\n",
        "7. Qual é o maior salário existente na tabela?\n",
        "\n",
        "8. Qual funcionário possui o maior salário?\n",
        "\n",
        "9. Liste os funcionários ordenados pela data de contratação.\n",
        "\n",
        "10. Quantos funcionários ganham mais de 20.000?\n",
        "\n",
        "11. Mostre os e-mails dos funcionários em letras maiúsculas.\n",
        "\n",
        "12. Mostre o nome completo de cada funcionário concatenando nome e sobrenome.\n",
        "\n",
        "13. Quantos funcionários não possuem gerente cadastrado?\n",
        "\n",
        "14. Qual é a média salarial de cada departamento?\n",
        "\n",
        "15. Quais funcionários possuem sobrenome iniciando com a letra 'K'?\n",
        "\n",
        "16. Quais funcionários foram contratados na década de 1980?\n",
        "\n",
        "17. Qual é o salário anual (salário × 12) de cada funcionário?\n",
        "\n",
        "18. Quantos cargos diferentes existem na tabela?\n",
        "\n",
        "19. Quais funcionários possuem '123' no número de telefone?\n",
        "\n",
        "20. Liste os funcionários ordenados por departamento e por salário em ordem decrescente."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hub",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
